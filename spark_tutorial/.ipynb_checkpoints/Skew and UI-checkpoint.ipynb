{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f96b4090d50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (2, 0), (2, 1), (3, 0), (3, 1), (3, 2), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "num = 5\n",
    "\n",
    "partition_data = []\n",
    "\n",
    "for i in range(0,num):\n",
    "    for j in range(0,i):\n",
    "        partition_data.append((i,j))\n",
    "\n",
    "print partition_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_rdd= sc.parallelize(partition_data,2)\n",
    "partition_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_human_readable(rdd_obj):\n",
    "    partition_view = rdd_obj.mapPartitions(lambda l: [l]).map(list).collect()\n",
    "\n",
    "    for partition in partition_view:\n",
    "        print partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (2, 0), (2, 1), (3, 0), (3, 1)]\n",
      "[(3, 2), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "to_human_readable(partition_rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maps and filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0), (2, 1)]\n",
      "[(4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "filtered_rdd = partition_rdd.filter(lambda l: l[0]%2 == 0)\n",
    "# filtered_rdd.count()\n",
    "to_human_readable(filtered_rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[(1, 0)]\n",
      "[(2, 1)]\n",
      "[(3, 3)]\n",
      "[(4, 6)]\n"
     ]
    }
   ],
   "source": [
    "reduced_rdd = partition_rdd.reduceByKey(lambda a,b: a+b, numPartitions=5)\n",
    "reduced_rdd.count()\n",
    "to_human_readable(reduced_rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Skew in the UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate normal data :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = 1000\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(0,num):\n",
    "    for j in range(0,i):\n",
    "        data.append((i,j))\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical Big Data Problem (Skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_num = 10000000\n",
    "\n",
    "for i in range(0, big_num):\n",
    "    data.append((big_num, i))\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparkify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(data)\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_rdd = rdd.groupByKey().cache()\n",
    "mapped_rdd = grouped_rdd.map(lambda line: (line[0], [(i + 10) for i in line[1]])).cache()\n",
    "mapped_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapped_rdd = grouped_rdd.map(lambda line: (line[0], [(i + 10) for i in line[1]])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapped_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
